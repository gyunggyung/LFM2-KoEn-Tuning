[ğŸ‡ºğŸ‡¸ English](README_EN.md)

# ğŸ‡°ğŸ‡· LFM2-KoEn-Tuning

**LiquidAI LFM2-1.2B ê¸°ë°˜ í•œêµ­ì–´-ì˜ì–´ ì–‘ë°©í–¥ ë²ˆì—­ ëª¨ë¸ íŒŒì¸íŠœë‹**

[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Models-Hugging%20Face-yellow)](https://huggingface.co/gyung)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)

> âš ï¸ **Note**: í•´ë‹¹ ë ˆí¬ëŠ” ê¸°ì¡´ì— í•™ìŠµí–ˆë˜ ì½”ë“œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì•ˆí‹°ê·¸ë ˆë¹„í‹°(Antigravity)ì—ì„œ Claude Opus 4.5ë¥¼ ì¨ì„œ ë§Œë“  ì½”ë“œë“¤ì…ë‹ˆë‹¤. ì•„ì§ Colabê³¼ Kaggleì—ì„œ ì‹¤í–‰ì„ í•˜ë©° ê²€ì¦í•´ë³´ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•´ë‹¹ ì‹¤í—˜ì„ ë§ˆì¹˜ê³  í•´ë‹¹ ë§í¬ë¥¼ í¬í•¨í•´ì„œ ì¶”ê°€ ì—…ë°ì´íŠ¸ë¥¼ í•  ì˜ˆì •ì…ë‹ˆë‹¤.

---

## ğŸ† í•µì‹¬ ì„±ê³¼

> **1.2B ëª¨ë¸ì´ 4B ëª¨ë¸ì„ ì••ë„!** Gemma-3 (4B)ë³´ë‹¤ **1.78 CHrF++** ë†’ìŒ  
> ë‹¨ **400 Step (0.78 Epoch)** ë§Œì— SOTA ë‹¬ì„±

---

## ğŸ“Š ë²¤ì¹˜ë§ˆí¬ (Flores-200, 1012 Samples)

### ì „ì²´ ëª¨ë¸ ë¹„êµ (CHrF++ ê¸°ì¤€ ì •ë ¬)

| Rank | Model | CHrF++ | BLEU | Params | ë¹„ê³  |
|:----:|-------|:------:|:----:|:------:|------|
| 1 | Google Translate | 39.27 | 18.18 | - | ìƒìš© ì„œë¹„ìŠ¤ (Target) |
| 2 | Yanolja-4B-GGUF | 38.61 | 16.03 | 4B | Open Source SOTA |
| 3 | NLLB-200 (3.3B) | 35.09 | 11.68 | 3.3B | ë²ˆì—­ ì „ìš© ëª¨ë¸ |
| **4** | **ğŸ† LFM2-v8-rl-10k-adapter** | **34.61** | **13.21** | **1.2B** | **ë³¸ í”„ë¡œì íŠ¸ SOTA** |
| 5 | LFM2-v6.4-merged | 33.53 | 12.31 | 1.2B | SFT Base |
| 6 | Gemma-3-4B-it-GGUF | 32.83 | 11.36 | 4B | Google ìµœì‹  4B |
| 7 | LFM2-v6.1-curriculum | 32.48 | 11.89 | 1.2B | SFT Curriculum |
| 8 | NLLB-200-Distilled-600M | 31.97 | 10.32 | 600M | ê²½ëŸ‰ ë²ˆì—­ ëª¨ë¸ |
| 9 | LFM2-v4-100k | 31.53 | 11.13 | 1.2B | ì´ˆê¸° SFT |
| 10 | LFM2-1.2B (Base) | 27.23 | 6.43 | 1.2B | ë² ì´ìŠ¤ë¼ì¸ |
| 11 | Qwen3-4B-GGUF | 25.62 | 7.46 | 4B | Base Model |
| 12 | Gemma-3-1B-it-GGUF | 24.07 | 6.94 | 1B | 1B ëª¨ë¸ |
| 13 | Qwen3-1.7B-GGUF | 21.19 | - | 1.7B | Base Model |
| 14 | Qwen3-0.6B-GGUF | 13.48 | 1.98 | 0.6B | Base Model |

### GGUF ì–‘ìí™” ì„±ëŠ¥ (v8 merged ê¸°ì¤€)

| Quantization | CHrF++ | BLEU | Size | ë¹„ê³  |
|--------------|:------:|:----:|:----:|------|
| fp32 (ì›ë³¸) | 34.32 | 13.10 | 4.68G | ë°˜ë³µ ë²„ê·¸ ìˆìŒ |
| **Q8_0** ğŸ† | **34.39** | 12.93 | 1.25G | í’ˆì§ˆ+ì•ˆì •ì„± ìµœê³  |
| Q5_K_M | 34.08 | 12.78 | 843M | ê· í˜• ì¶”ì²œ |
| Q4_K_M | 33.97 | 12.56 | 731M | ê²½ëŸ‰í™”/ëª¨ë°”ì¼ |

> **ê²°ë¡ **: 4/5/8ë¹„íŠ¸ ì–‘ìí™” ëª¨ë‘ fp32ì™€ ì‚¬ì‹¤ìƒ ë™ì¼í•œ ì„±ëŠ¥!

---

## ğŸ“ˆ í•™ìŠµ ê³¼ì •ë³„ ì„±ëŠ¥ í–¥ìƒ

| Step | Epoch | CHrF++ | BLEU | ë¹„ê³  |
|:----:|:-----:|:------:|:----:|------|
| 0 | 0.00 | 33.53 | 12.63 | v6.4 Base |
| 200 | 0.39 | 34.10 | 12.93 | +0.57 í–¥ìƒ |
| 300 | 0.59 | 34.19 | 13.24 | Historic High |
| **400** | **0.78** | **34.61** | **13.21** | **ğŸ† SOTA** |

---

## âœ¨ v8 ëª¨ë¸ ê°•ì 

- **ì¡´ëŒ“ë§ ì¼ê´€ì„±**: "í•©ë‹ˆë‹¤", "í–ˆìŠµë‹ˆë‹¤" ì–´ë¯¸ê°€ 1012ê°œ ì „ì²´ ìƒ˜í”Œì—ì„œ ì¼ê´€ ì ìš©
- **ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥**: ë³µì¡í•œ ë¬¸ì¥ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬
- **ë¬¸ë§¥ ì¸ì‹**: "While"ì„ ë¬¸ë§¥ì— ë”°ë¼ "ë°˜ë©´", "ë™ì•ˆ" ë“±ìœ¼ë¡œ ìœ ì—°í•˜ê²Œ ë²ˆì—­
- **ì „ë¬¸ ìš©ì–´**: "rachis"ë¥¼ "ìš°ì¶•"ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë²ˆì—­

### âš ï¸ ì•Œë ¤ì§„ í•œê³„

- **ê³ ìœ ëª…ì‚¬ í™˜ê°**: "George W. Bush" â†’ "ì¡°ì§€ ì›Œì‹±í„´" (ë² ì´ìŠ¤ ëª¨ë¸ í¸í–¥)
- **í•´ê²° ë°©ì•ˆ**: SFT + DPOë¥¼ í†µí•œ í™˜ê° êµì • ì˜ˆì • (v9)

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°
```
â”œâ”€â”€ colab/              # Colab ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ GRPO_v8_adapter_github.ipynb      # RL GRPO (SOTA)
â”‚   â”œâ”€â”€ GRPO_v8_unsloth_vllm_github.ipynb # RL Unsloth+vLLM
â”‚   â”œâ”€â”€ SFT_colab_github.ipynb            # SFT Colab ìŠ¤íƒ€ì¼ â­
â”‚   â””â”€â”€ SFT_v6.1_curriculum_github.ipynb  # SFT Kaggle ìŠ¤íƒ€ì¼
â”œâ”€â”€ kaggle/             # Kaggle ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ SFT_v6.1_curriculum.ipynb     # SFT v6.1
â”‚   â””â”€â”€ SFT_v6_200k.ipynb             # SFT v6 200k
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ benchmark_flores200.ipynb     # ë²¤ì¹˜ë§ˆí¬
â”œâ”€â”€ quantization/
â”‚   â””â”€â”€ convert_to_gguf_github.ipynb  # GGUF ë³€í™˜ (GitHubìš©)
â””â”€â”€ dataset/
    â”œâ”€â”€ samples/                      # í•™ìŠµ ë°ì´í„° ìƒ˜í”Œ
    â””â”€â”€ upload_to_hf_github.py        # HF ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (GitHubìš©)
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### SOTA ëª¨ë¸ ì‚¬ìš© (v8 Adapter)

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# Base ëª¨ë¸ ë¡œë“œ
base_model = AutoModelForCausalLM.from_pretrained(
    "gyung/lfm2-1.2b-koen-mt-v6.4-merged",
    device_map="auto",
    torch_dtype="auto"
)
tokenizer = AutoTokenizer.from_pretrained("gyung/lfm2-1.2b-koen-mt-v6.4-merged")

# Adapter ë¡œë“œ ë° ë³‘í•©
model = PeftModel.from_pretrained(base_model, "gyung/lfm2-1.2b-koen-mt-v8-rl-10k-adapter")
model = model.merge_and_unload()

# ë²ˆì—­
messages = [
    {"role": "system", "content": "Translate to Korean."},
    {"role": "user", "content": "Hello, world!"}
]
inputs = tokenizer.apply_chat_template(messages, return_tensors="pt")
outputs = model.generate(inputs, max_new_tokens=256, temperature=0.3)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

### GGUF ì‚¬ìš© (llama.cpp)

```python
from llama_cpp import Llama
from huggingface_hub import hf_hub_download

model_path = hf_hub_download(
    "gyung/lfm2-1.2b-koen-mt-v8-rl-10k-merged-GGUF",
    "lfm2-1.2b-koen-mt-v8-rl-10k-merged-Q8_0.gguf"
)

llm = Llama(model_path=model_path, n_ctx=4096, n_gpu_layers=-1)

prompt = """<|im_start|>system
Translate to Korean.<|im_end|>
<|im_start|>user
Hello, world!<|im_end|>
<|im_start|>assistant
"""
output = llm(prompt, max_tokens=256, stop=["<|im_end|>"], temperature=0.3)
print(output['choices'][0]['text'])
```

---

## ğŸ“Š ë°ì´í„°ì…‹

`dataset/samples/`ì— í•™ìŠµ ë°ì´í„° ìƒ˜í”Œ í¬í•¨:

| íŒŒì¼ | ìš©ë„ | ê°œìˆ˜ |
|------|------|------|
| `sample_sft_100_bidirectional.jsonl` | SFT | 100 |
| `sample_grpo_100_bidirectional.jsonl` | GRPO | 100 |

### HuggingFace ì—…ë¡œë“œ

```bash
# .env íŒŒì¼ì— HF=your_token ì„¤ì • í›„
cd dataset
python upload_to_hf_github.py --repo YOUR_ID/your-dataset-name
```

---

## âš™ï¸ í•™ìŠµ ì„¤ì •

### GRPO (v8 SOTA)

| í•­ëª© | ê°’ |
|------|-----|
| Base Model | gyung/lfm2-1.2b-koen-mt-v6.4-merged |
| Method | GRPO (Group Relative Policy Optimization) |
| Reward | COMET + CHrF++ |
| Dataset | 10,000 samples (ì–‘ë°©í–¥) |
| Steps | 400 |
| LoRA Rank/Alpha | 32 / 64 |

### SFT (v6.4 Base)

```python
SFTConfig(
    per_device_train_batch_size=1,
    gradient_accumulation_steps=16,
    learning_rate=1e-5,
    lr_scheduler_type="cosine",
    warmup_ratio=0.1,
    optim="paged_adamw_8bit",
    fp16=True,  # T4 ìµœì í™”
)
```

---

## ğŸ”— ëª¨ë¸ ë§í¬

| ëª¨ë¸ | ì„¤ëª… | ë§í¬ |
|------|------|------|
| **v8 Adapter** ğŸ† | SOTA (CHrF++ 34.61) | [HuggingFace](https://huggingface.co/gyung/lfm2-1.2b-koen-mt-v8-rl-10k-adapter) |
| v8 GGUF | ì–‘ìí™” ë²„ì „ | [HuggingFace](https://huggingface.co/gyung/lfm2-1.2b-koen-mt-v8-rl-10k-merged-GGUF) |
| v6.4 Merged | Base ëª¨ë¸ | [HuggingFace](https://huggingface.co/gyung/lfm2-1.2b-koen-mt-v6.4-merged) |
| v4 100k | ì´ˆê¸° SFT | [HuggingFace](https://huggingface.co/gyung/lfm2-1.2b-koen-mt-v4-100k) |
| LFM2-1.2B | ì›ë³¸ ë² ì´ìŠ¤ | [LiquidAI](https://huggingface.co/LiquidAI/LFM2-1.2B) |

---

## ğŸ“ Citation

```bibtex
@misc{lfm2-koen-v8-rl,
  author = {gyung},
  title = {LFM2-1.2B-KoEn-MT: GRPO-Enhanced Korean-English Translation},
  year = {2025},
  publisher = {Hugging Face},
  url = {https://huggingface.co/gyung/lfm2-1.2b-koen-mt-v8-rl-10k-adapter}
}
```

---

## ğŸ“œ ë¼ì´ì„ ìŠ¤

ì´ ëª¨ë¸ì€ **Liquid AI LFM Open License v1.0**ì„ ë”°ë¦…ë‹ˆë‹¤.

- âœ… í•™ìˆ  ì—°êµ¬ ë° ê°œì¸ì  ì‚¬ìš©: ë¬´ì œí•œ
- âœ… ìƒì—…ì  ì´ìš©: ì—° ë§¤ì¶œ $10M ë¯¸ë§Œ ë¬´ë£Œ
- âš ï¸ ì—° ë§¤ì¶œ $10M ì´ˆê³¼: ë³„ë„ ë¼ì´ì„ ìŠ¤ í•„ìš”

---

*Last Updated: 2026-01-03*
